{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0520 23:23:14.340660 23972 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('simple_ms_t.csv')\n",
    "data = frame.values[:, 1]\n",
    "labels = frame.values[:, 0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  17   19   20   21   27   31   40   50   53   57   58   59   61   65\n",
      "   81   84   86  105  106  112  113  115  119  123  131  136  138  140\n",
      "  144  149  150  155  156  161  162  170  171  172  175  176  177  178\n",
      "  179  189  196  264  272  276  279  287  289  344  361  364  376  397\n",
      "  398  403  404  407  413  421  495  509  607  641  676  710  737  738\n",
      "  800  826 1029 1040 1142 1303 1308 1408 1431]\n"
     ]
    }
   ],
   "source": [
    "x, c = np.unique(labels, return_counts=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-large/3\")\n",
    "embed = hub.Module(\"http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0520 23:37:40.210232 23972 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
    "embedding = layers.Lambda(UniversalEmbedding, output_shape=(512,))(input_text)\n",
    "dense = layers.Dense(256, activation='relu')(embedding)\n",
    "pred = layers.Dense(1432, activation='softmax')(dense)\n",
    "model = tf.keras.models.Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='sparse_categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "34373/34373 [==============================] - 65s 2ms/sample - loss: 0.7492 - acc: 0.8243\n",
      "Epoch 2/7\n",
      "34373/34373 [==============================] - 61s 2ms/sample - loss: 0.3205 - acc: 0.9098\n",
      "Epoch 3/7\n",
      "34373/34373 [==============================] - 62s 2ms/sample - loss: 0.2525 - acc: 0.9277\n",
      "Epoch 4/7\n",
      "34373/34373 [==============================] - 62s 2ms/sample - loss: 0.2108 - acc: 0.9373\n",
      "Epoch 5/7\n",
      "34373/34373 [==============================] - 62s 2ms/sample - loss: 0.1767 - acc: 0.9467\n",
      "Epoch 6/7\n",
      "34373/34373 [==============================] - 62s 2ms/sample - loss: 0.1517 - acc: 0.9533\n",
      "Epoch 7/7\n",
      "34373/34373 [==============================] - 62s 2ms/sample - loss: 0.1295 - acc: 0.9600\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  history = model.fit(data, \n",
    "            labels,\n",
    "            epochs=7,\n",
    "            batch_size=32)\n",
    "  model.save_weights('./model_ru.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x00000256B95DFF28>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.2196215e-11 2.3403859e-11 3.8052606e-11 ... 4.9119884e-12\n",
      "  5.2511342e-11 1.2088590e-11]\n",
      " [1.8795738e-06 2.0970240e-06 1.1910984e-06 ... 1.6356486e-06\n",
      "  3.7065274e-06 3.9824440e-06]\n",
      " [7.5145704e-07 8.7550950e-07 4.4306333e-07 ... 5.8026023e-07\n",
      "  1.2646774e-06 4.3133809e-06]\n",
      " [2.5015407e-07 2.2081262e-07 3.0597388e-07 ... 1.3323178e-07\n",
      "  4.6713456e-07 4.3256939e-04]\n",
      " [5.9433012e-07 3.2725976e-07 3.2161233e-07 ... 5.9862720e-07\n",
      "  1.0268095e-06 3.4705490e-06]\n",
      " [3.0124443e-06 3.5109481e-06 3.3715964e-06 ... 2.5974587e-06\n",
      "  4.9849928e-06 2.0923584e-03]]\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"на каком языке говорят в Голландии\",\n",
    "            \"в каком году родилась Екатерина I\",\n",
    "            \"в каком году родился Нельсон\",\n",
    "            \"в каких продуктах содержится белок\",\n",
    "            \"сколько лет медведеву\",\n",
    "            \"сколько медалей завоевала российская сборная 2012\"]\n",
    "\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    \n",
    "    model.load_weights('./model_ru.h5')\n",
    "    \n",
    "    predicts = model.predict(new_text, batch_size=32)\n",
    "    print(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 361  509 1308 ...  136  407  364]\n",
      " [ 161   81  361 ...  138   59   19]\n",
      " [ 161   81  361 ...   40  196   19]\n",
      " [  84  176 1071 ...  495  196   27]\n",
      " [1308  161  361 ...   65  421  196]\n",
      " [ 407  161 1040 ...   19  178  196]]\n"
     ]
    }
   ],
   "source": [
    "predict_logits = predicts.argsort()\n",
    "print(predict_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
